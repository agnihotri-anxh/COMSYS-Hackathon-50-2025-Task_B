{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"evaluate_model.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1UGwuNxcfik7S_3z3Fm-e-qVN4sewjQoc\n",
    "\n",
    "# Model Evaluation and Analysis\n",
    "\n",
    "This notebook evaluates the trained face recognition model and provides detailed analysis of its performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 1. Load Trained Model\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d044731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading trained model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a875da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model = load_model('models/best_face_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label encoder\n",
    "with open('models/enhanced_label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"üìä Model input shape: {model.input_shape}\")\n",
    "print(f\"üìä Model output shape: {model.output_shape}\")\n",
    "print(f\"üè∑Ô∏è Number of classes: {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 2. Load Validation Data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation set saved from training\n",
    "if os.path.exists('X_val.npy') and os.path.exists('y_val.npy'):\n",
    "    X_val = np.load('X_val.npy')\n",
    "    y_val = np.load('y_val.npy')\n",
    "    if os.path.exists('distortion_types_val.npy'):\n",
    "        distortion_types = np.load('distortion_types_val.npy', allow_pickle=True)\n",
    "    else:\n",
    "        distortion_types = ['unknown'] * len(y_val)\n",
    "    print(f\"‚úÖ Loaded validation set from disk: {X_val.shape[0]} samples\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Validation set files 'X_val.npy' and 'y_val.npy' not found. Please run training first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88327740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 3. Preprocess Data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f511770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "X_val_normalized = X_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val is already integer-encoded (from training)\n",
    "y_val_encoded = y_val.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üìä Validation data shape: {X_val_normalized.shape}\")\n",
    "print(f\"üìä Labels shape: {y_val_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 4. Model Evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Evaluating model performance...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b81463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = model.predict(X_val_normalized)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "prediction_probabilities = np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129dfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_encoded, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3aa285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate macro-averaged F1-score\n",
    "macro_f1 = f1_score(y_val_encoded, predicted_classes, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54941708",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üèÜ Top-1 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"‚≠ê Macro-averaged F1-Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86190e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 5. Detailed Performance Analysis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_val_encoded, predicted_classes,\n",
    "                          target_names=label_encoder.classes_[:10],  # Show first 10 classes\n",
    "                          zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 6. Confusion Matrix\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881c6df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_val_encoded, predicted_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_[:10],\n",
    "            yticklabels=label_encoder.classes_[:10])\n",
    "plt.title('Confusion Matrix (First 10 Classes)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62344956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 7. Confidence Analysis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(prediction_probabilities, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Confidence\n",
    "plt.subplot(1, 3, 2)\n",
    "correct_mask = y_val_encoded == predicted_classes\n",
    "plt.scatter(prediction_probabilities[correct_mask],\n",
    "           [1]*sum(correct_mask), alpha=0.6, color='green', label='Correct')\n",
    "plt.scatter(prediction_probabilities[~correct_mask],\n",
    "           [0]*sum(~correct_mask), alpha=0.6, color='red', label='Incorrect')\n",
    "plt.title('Accuracy vs Confidence', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Correct (1) / Incorrect (0)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52f3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb540a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig('results/confidence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 8. Save Evaluation Results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ca320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ Saving evaluation results...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78259f1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with open('results/evaluation_results.txt', 'w') as f:\n",
    "    f.write(f\"Face Recognition Model Evaluation Results\\n\")\n",
    "    f.write(f\"==========================================\\n\")\n",
    "    f.write(f\"Top-1 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
    "    f.write(f\"Macro-averaged F1-Score: {macro_f1:.4f}\\n\")\n",
    "    f.write(f\"Total Validation Images: {len(X_val)}\\n\")\n",
    "    f.write(f\"Number of Classes: {len(label_encoder.classes_)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Evaluation completed!\")\n",
    "print(\"üìÅ Results saved to:\")\n",
    "print(\"  ‚Ä¢ results/confusion_matrix.png\")\n",
    "print(\"  ‚Ä¢ results/confidence_analysis.png\")\n",
    "print(\"  ‚Ä¢ results/evaluation_results.txt\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
