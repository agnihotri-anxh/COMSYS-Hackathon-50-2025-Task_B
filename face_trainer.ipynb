{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"face_trainer.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/17EdTwSvxibQlCuaADIKqSrAwoNS14uXE\n",
    "\n",
    "# Face Recognition Model Trainer\n",
    "\n",
    "This notebook trains a robust face recognition model that can identify people even when their images are distorted by various environmental conditions like blur, fog, low light, noise, rain, etc.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The goal is to create a face recognition system that:\n",
    "- Works with a large dataset of people\n",
    "- Handles multiple types of image distortions\n",
    "- Achieves high accuracy (>90%) on validation data\n",
    "- Uses efficient training techniques\n",
    "\n",
    "## Technical Approach\n",
    "\n",
    "- **Transfer Learning**: Uses ResNet50V2 pre-trained on ImageNet\n",
    "- **Mixed Precision**: 2x faster training with 50% less memory usage\n",
    "- **Advanced Augmentation**: Comprehensive data augmentation for robustness\n",
    "- **Smart Callbacks**: Model checkpointing, early stopping, and learning rate reduction\n",
    "\n",
    "## 1. Import Libraries and Setup\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d75073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 2. Configuration Settings\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for full dataset training\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32  # Increased batch size for efficiency\n",
    "EPOCHS = 75\n",
    "LEARNING_RATE = 5e-5  # Lower learning rate for fine-tuning\n",
    "USE_MIXED_PRECISION = True  # Enable mixed precision for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26268fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ğŸ“Š Configuration:\")\n",
    "print(f\"   Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Mixed Precision: {USE_MIXED_PRECISION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed precision setup\n",
    "if USE_MIXED_PRECISION:\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "    print(\"ğŸš€ Mixed precision enabled for faster training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f27f24",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 3. Dataset Loading Function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3d89d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load complete dataset with all people and their distorted images\n",
    "\n",
    "    Returns:\n",
    "        tuple: (images, labels, distortion_types)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Loading complete dataset...\")\n",
    "\n",
    "    dataset_path = \"dataset/Task_B/train\"\n",
    "    people_dirs = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "\n",
    "    print(f\"ğŸ“ Found {len(people_dirs)} people in dataset\")\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    distortion_types = []\n",
    "\n",
    "    # Track statistics\n",
    "    total_images = 0\n",
    "    skipped_people = 0\n",
    "\n",
    "    for i, person_dir in enumerate(people_dirs):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"â³ Processing person {i+1}/{len(people_dirs)}: {person_dir}\")\n",
    "\n",
    "        person_path = os.path.join(dataset_path, person_dir)\n",
    "\n",
    "        # Load main image\n",
    "        main_image_path = os.path.join(person_path, f\"{person_dir}.jpg\")\n",
    "        if os.path.exists(main_image_path):\n",
    "            try:\n",
    "                img = cv2.imread(main_image_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                    images.append(img)\n",
    "                    labels.append(person_dir)\n",
    "                    distortion_types.append('clean')\n",
    "                    total_images += 1\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error loading main image {main_image_path}: {e}\")\n",
    "\n",
    "        # Load distorted images\n",
    "        distortion_path = os.path.join(person_path, \"distortion\")\n",
    "        if os.path.exists(distortion_path):\n",
    "            distortion_files = glob(os.path.join(distortion_path, \"*.jpg\")) + glob(os.path.join(distortion_path, \"*.png\"))\n",
    "\n",
    "            for img_file in distortion_files:\n",
    "                try:\n",
    "                    img = cv2.imread(img_file)\n",
    "                    if img is not None:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                        images.append(img)\n",
    "                        labels.append(person_dir)\n",
    "                        total_images += 1\n",
    "\n",
    "                        # Determine distortion type\n",
    "                        filename = os.path.basename(img_file)\n",
    "                        if 'blurred' in filename:\n",
    "                            distortion_types.append('blur')\n",
    "                        elif 'foggy' in filename:\n",
    "                            distortion_types.append('fog')\n",
    "                        elif 'lowlight' in filename:\n",
    "                            distortion_types.append('lowlight')\n",
    "                        elif 'noisy' in filename:\n",
    "                            distortion_types.append('noise')\n",
    "                        elif 'rainy' in filename:\n",
    "                            distortion_types.append('rain')\n",
    "                        elif 'resized' in filename:\n",
    "                            distortion_types.append('resized')\n",
    "                        elif 'sunny' in filename:\n",
    "                            distortion_types.append('overexposed')\n",
    "                        else:\n",
    "                            distortion_types.append('unknown')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error loading distorted image {img_file}: {e}\")\n",
    "        else:\n",
    "            skipped_people += 1\n",
    "\n",
    "    print(f\"\\nğŸ“ˆ Dataset Statistics:\")\n",
    "    print(f\"   Total people processed: {len(people_dirs)}\")\n",
    "    print(f\"   People with distortion data: {len(people_dirs) - skipped_people}\")\n",
    "    print(f\"   Total images loaded: {total_images}\")\n",
    "    print(f\"   Unique classes: {len(set(labels))}\")\n",
    "\n",
    "    # Show distortion distribution\n",
    "    distortion_counts = pd.Series(distortion_types).value_counts()\n",
    "    print(f\"\\nğŸ­ Distortion distribution:\")\n",
    "    for dist_type, count in distortion_counts.items():\n",
    "        print(f\"   {dist_type}: {count} images\")\n",
    "\n",
    "    return np.array(images), np.array(labels), distortion_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdb56a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 4. Model Creation Function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd2bc6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_model(num_classes):\n",
    "    \"\"\"\n",
    "    Create enhanced model for full dataset training\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of unique people/classes\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Compiled model ready for training\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ—ï¸ Creating enhanced model for {num_classes} classes...\")\n",
    "\n",
    "    # Load pre-trained ResNet50V2\n",
    "    base_model = ResNet50V2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    # Freeze early layers, train later layers\n",
    "    for layer in base_model.layers[:-30]:  # Freeze all except last 30 layers\n",
    "        layer.trainable = False\n",
    "\n",
    "    print(f\"ğŸ”’ Frozen {len(base_model.layers[:-30])} layers, training {len(base_model.layers[-30:])} layers\")\n",
    "\n",
    "    # Create enhanced model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Output layer\n",
    "    if USE_MIXED_PRECISION:\n",
    "        # Use float32 for the final layer when using mixed precision\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        predictions = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    else:\n",
    "        predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile with optimized settings\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Model created and compiled successfully!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fec9b5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 5. Data Generator Function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbd3fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_data_generators(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Create advanced data generators with comprehensive augmentation\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_generator, val_generator)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Creating data generators with augmentation...\")\n",
    "\n",
    "    # Training data generator with advanced augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest',\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "    # Validation data generator (minimal augmentation)\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow(\n",
    "        X_val, y_val,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Data generators created successfully!\")\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd2ea9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 6. Training Function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533281ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \"\"\"\n",
    "    Train enhanced model on full dataset\n",
    "\n",
    "    Returns:\n",
    "        tuple: (trained_model, label_encoder, history, X, X_train, X_val, num_classes, distortion_types)\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ Starting full dataset robust training...\")\n",
    "\n",
    "    # Load complete dataset\n",
    "    X, y, distortion_types = load_dataset()\n",
    "\n",
    "    # Remove classes with only one sample\n",
    "    label_counts = Counter(y)\n",
    "    valid_classes = [label for label, count in label_counts.items() if count > 1]\n",
    "    mask = np.isin(y, valid_classes)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    if isinstance(distortion_types, np.ndarray):\n",
    "        distortion_types = distortion_types[mask]\n",
    "    else:\n",
    "        distortion_types = [d for d, m in zip(distortion_types, mask) if m]\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "\n",
    "    print(f\"\\nğŸ“Š Dataset Info:\")\n",
    "    print(f\"   Number of classes: {num_classes}\")\n",
    "    print(f\"   Class distribution: min={np.bincount(y_encoded).min()}, max={np.bincount(y_encoded).max()}, avg={np.bincount(y_encoded).mean():.1f}\")\n",
    "\n",
    "    # Stratified split (guaranteed to work now)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    # Save validation set for evaluation\n",
    "    np.save('X_val.npy', X_val)\n",
    "    np.save('y_val.npy', y_val)\n",
    "\n",
    "    print(f\"ğŸ“ˆ Data Split:\")\n",
    "    print(f\"   Training samples: {len(X_train)}\")\n",
    "    print(f\"   Validation samples: {len(X_val)}\")\n",
    "\n",
    "    # Create data generators\n",
    "    train_generator, val_generator = create_data_generators(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Create enhanced model\n",
    "    model = create_model(num_classes)\n",
    "\n",
    "    # Print model summary\n",
    "    print(\"\\nğŸ“‹ Model Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Advanced callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            'models/best_face_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        CSVLogger(\n",
    "            'results/training_log.csv',\n",
    "            append=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    print(\"\\nğŸ¯ Starting training...\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, label_encoder, history, X, X_train, X_val, num_classes, distortion_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e010db4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 7. Visualization Function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613992b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training history with comprehensive visualizations\n",
    "\n",
    "    Args:\n",
    "        history: Training history from model.fit()\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š Creating training visualizations...\")\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)\n",
    "    plt.title('Validation Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.axhline(y=0.9, color='green', linestyle='--', label='90% Target', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"âœ… Training visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd1101",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## 8. Results Saving Function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f8d7d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_results(X, X_train, X_val, num_classes, history, distortion_types):\n",
    "    \"\"\"\n",
    "    Save comprehensive training results\n",
    "\n",
    "    Args:\n",
    "        X: Complete dataset\n",
    "        X_train, X_val: Training and validation splits\n",
    "        num_classes: Number of classes\n",
    "        history: Training history\n",
    "        distortion_types: List of distortion types\n",
    "    \"\"\"\n",
    "    print(\"ğŸ’¾ Saving comprehensive results...\")\n",
    "\n",
    "    with open('results/training_results.txt', 'w') as f:\n",
    "        f.write(f\"Face Recognition Training Results\\n\")\n",
    "        f.write(f\"==================================\\n\")\n",
    "        f.write(f\"Total images: {len(X)}\\n\")\n",
    "        f.write(f\"Number of people: {num_classes}\\n\")\n",
    "        f.write(f\"Training samples: {len(X_train)}\\n\")\n",
    "        f.write(f\"Validation samples: {len(X_val)}\\n\")\n",
    "        f.write(f\"Batch size: {BATCH_SIZE}\\n\")\n",
    "        f.write(f\"Learning rate: {LEARNING_RATE}\\n\")\n",
    "        f.write(f\"Mixed precision: {USE_MIXED_PRECISION}\\n\")\n",
    "        f.write(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\\n\")\n",
    "        f.write(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\\n\")\n",
    "        f.write(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\\n\")\n",
    "        f.write(f\"Training epochs: {len(history.history['accuracy'])}\\n\")\n",
    "\n",
    "        # Distortion statistics\n",
    "        f.write(f\"\\nDistortion Statistics:\\n\")\n",
    "        distortion_df = pd.DataFrame({'distortion': distortion_types})\n",
    "        distortion_counts = distortion_df['distortion'].value_counts()\n",
    "        for dist_type, count in distortion_counts.items():\n",
    "            f.write(f\"  {dist_type}: {count} images\\n\")\n",
    "\n",
    "    print(\"âœ… Results saved to 'results/training_results.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a120231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## 9. Main Execution\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7613c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Directories created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model, label_encoder, history, X, X_train, X_val, num_classes, distortion_types = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaff65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/enhanced_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(\"âœ… Label encoder saved to 'models/enhanced_label_encoder.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_results(X, X_train, X_val, num_classes, history, distortion_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde30b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(f\"\\nğŸ‰ Training completed!\")\n",
    "print(f\"ğŸ† Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"ğŸ“Š Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9670d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if max(history.history['val_accuracy']) >= 0.9:\n",
    "    print(\"ğŸ¯ SUCCESS: Model achieved 90%+ accuracy on full dataset!\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Model achieved {max(history.history['val_accuracy']):.1%} accuracy (target: 90%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“ Files created:\")\n",
    "print(\"  â€¢ models/best_face_model.h5 - Trained model\")\n",
    "print(\"  â€¢ results/training_history.png - Training plots\")\n",
    "print(\"  â€¢ results/training_log.csv - Training history\")\n",
    "print(\"  â€¢ results/training_results.txt - Detailed results\")\n",
    "print(\"\\nğŸš€ This model is ready for face recognition tasks!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
